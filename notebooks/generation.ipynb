{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/github/jamesparsloe/llm.speech/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from llmspeech.model import GPT\n",
    "from llmspeech.text import tokenize, detokenize\n",
    "from llmspeech.audio import unflatten_and_remove_offsets, CODEC_SAMPLE_RATE\n",
    "from llmspeech.utils import count_parameters\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "from snac import SNAC\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from contextlib import nullcontext\n",
    "from llmspeech.generation import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compile = True\n",
    "# precision = torch.bfloat16\n",
    "precision = torch.float32\n",
    "device = \"cuda\"\n",
    "\n",
    "ctx = (\n",
    "    torch.cuda.amp.autocast(dtype=torch.bfloat16)\n",
    "    if precision == torch.float32\n",
    "    else nullcontext()\n",
    ")\n",
    "\n",
    "rope_theta = 10000.0  # twice the default\n",
    "\n",
    "\n",
    "# name = \"gpt-small-055000.pt\"\n",
    "# step = name.split(\"-\")[-1].split(\".\")[0]\n",
    "# model = (\n",
    "#     GPT.from_huggingface(name, rope_theta=rope_theta)\n",
    "#     .eval()\n",
    "#     .to(dtype=precision, device=device)\n",
    "# )\n",
    "name = \"./runs/850e3bv2/gpt-000200.pt\"\n",
    "name = \"./runs/ofmpactw/gpt-000500.pt\"\n",
    "name = \"./runs/bw6215fn/gpt-001000.pt\"\n",
    "name = \"./runs/f7zjo4js/gpt-001000.pt\"  # with style tags\n",
    "\n",
    "step = name.split(\"-\")[-1].split(\".\")[0]\n",
    "model = (\n",
    "    GPT.from_pretrained(name, rope_theta=rope_theta)\n",
    "    .eval()\n",
    "    .to(dtype=precision, device=device)\n",
    ")\n",
    "config = model.config\n",
    "\n",
    "codec = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\").eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_1984 = \"It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his breast in an effort to escape the vile wind, slipped quickly through the glass doors of Victory Mansions, though not quickly enough to prevent a swirl of gritty dust from entering along with him.\"\n",
    "_1984_2 = \"The hallway smelt of boiled cabbage and old rag mats. At one end of it a coloured poster, too large for indoor display, had been tacked to the wall. It depicted simply an enormous face, more than a metre wide: the face of a man of about forty-five, with a heavy black moustache and ruggedly handsome features.\"\n",
    "\n",
    "harry_potter = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
    "\n",
    "texts = [\n",
    "    \"Does this work?\",\n",
    "    _1984,\n",
    "    _1984_2,\n",
    "    harry_potter,\n",
    "]\n",
    "\n",
    "if config.with_style_prompts:\n",
    "    print(f\"Using style prompts\")\n",
    "    texts = [\n",
    "        f\"[{style}]{text}\"\n",
    "        for text in texts\n",
    "        for style in [\"default\", \"narration\", \"whisper\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "waveforms = []\n",
    "\n",
    "temperature, top_k = 1.0, 64\n",
    "max_new_tokens = 20 * 84\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"{len(text)=}\")\n",
    "        t1 = time.perf_counter()\n",
    "        input_ids = [config.bos_token_id] + tokenize(text) + [config.boa_token_id]\n",
    "        input_ids = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "        with ctx:\n",
    "            output_ids = generate(\n",
    "                model,\n",
    "                input_ids,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k,\n",
    "                compile=compile,\n",
    "            )\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        t2 = time.perf_counter()\n",
    "\n",
    "        latency = t2 - t1\n",
    "\n",
    "        tokens_per_second = output_ids.size(-1) / latency\n",
    "\n",
    "        print(\n",
    "            f\"{i=} {compile=} {text=} {output_ids.size(-1)} generated tokens {tokens_per_second=:.2f} {latency=:.2f}\"\n",
    "        )\n",
    "        step = 7\n",
    "        T_out = output_ids.size(-1)\n",
    "        rem = T_out % step\n",
    "        if rem > 0:\n",
    "            print(f\"{rem=}\")\n",
    "            output_ids = output_ids[:, :-rem]\n",
    "\n",
    "        codes = unflatten_and_remove_offsets(\n",
    "            output_ids[0],\n",
    "            n_text_tokens=config.n_text_tokens,\n",
    "            codebook_size=config.codebook_size,\n",
    "        )\n",
    "        waveform = codec.decode(codes)\n",
    "        waveform = waveform.squeeze(0).cpu()\n",
    "        waveforms.append(waveform)\n",
    "        torchaudio.save(\n",
    "            f\"{temperature=}-{top_k=}-{int(time.time())}.wav\",\n",
    "            waveform,\n",
    "            CODEC_SAMPLE_RATE,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
